name: Deploy to Production

on:
  push:
    branches: [main]
    paths:
      - 'backend/**'
      - 'frontend/**'
      - '.pipeline/k8s/**'
      - '.github/workflows/deploy.yml'

  # Allow manual trigger
  workflow_dispatch:
    inputs:
      deploy_backend:
        description: 'Deploy backend'
        type: boolean
        default: true
      deploy_frontend:
        description: 'Deploy frontend'
        type: boolean
        default: true

env:
  ACR_REGISTRY: financialagent-gxftdbbre4gtegea.azurecr.io
  ACR_NAMESPACE: klinecubic
  K8S_NAMESPACE: klinematrix-prod

jobs:
  # Detect which components changed
  detect-changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    outputs:
      backend: ${{ steps.changes.outputs.backend }}
      frontend: ${{ steps.changes.outputs.frontend }}
      backend_version: ${{ steps.versions.outputs.backend }}
      frontend_version: ${{ steps.versions.outputs.frontend }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Check for changes
        id: changes
        run: |
          # For manual dispatch, use inputs; otherwise detect from git
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "backend=${{ github.event.inputs.deploy_backend }}" >> $GITHUB_OUTPUT
            echo "frontend=${{ github.event.inputs.deploy_frontend }}" >> $GITHUB_OUTPUT
          else
            # Check if backend changed
            if git diff --name-only HEAD^ HEAD | grep -q "^backend/"; then
              echo "backend=true" >> $GITHUB_OUTPUT
            else
              echo "backend=false" >> $GITHUB_OUTPUT
            fi

            # Check if frontend changed
            if git diff --name-only HEAD^ HEAD | grep -q "^frontend/"; then
              echo "frontend=true" >> $GITHUB_OUTPUT
            else
              echo "frontend=false" >> $GITHUB_OUTPUT
            fi
          fi

      - name: Get versions
        id: versions
        run: |
          BACKEND_VERSION=$(grep '^version = ' backend/pyproject.toml | sed 's/version = "\(.*\)"/\1/')
          FRONTEND_VERSION=$(node -p "require('./frontend/package.json').version")
          echo "backend=$BACKEND_VERSION" >> $GITHUB_OUTPUT
          echo "frontend=$FRONTEND_VERSION" >> $GITHUB_OUTPUT
          echo "ğŸ“¦ Backend version: $BACKEND_VERSION"
          echo "ğŸ“¦ Frontend version: $FRONTEND_VERSION"

  # Build and push backend image
  build-backend:
    name: Build Backend
    needs: detect-changes
    if: needs.detect-changes.outputs.backend == 'true'
    runs-on: ubuntu-latest
    outputs:
      image: ${{ steps.build.outputs.image }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Azure ACR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.ACR_REGISTRY }}
          username: ${{ secrets.AZURE_ACR_USERNAME }}
          password: ${{ secrets.AZURE_ACR_PASSWORD }}

      - name: Build and Push Backend
        id: build
        uses: docker/build-push-action@v6
        with:
          context: ./backend
          file: ./backend/Dockerfile
          push: true
          tags: |
            ${{ env.ACR_REGISTRY }}/${{ env.ACR_NAMESPACE }}/backend:prod-v${{ needs.detect-changes.outputs.backend_version }}
            ${{ env.ACR_REGISTRY }}/${{ env.ACR_NAMESPACE }}/backend:prod-${{ github.sha }}
            ${{ env.ACR_REGISTRY }}/${{ env.ACR_NAMESPACE }}/backend:prod-latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Output image tag
        run: |
          IMAGE="${{ env.ACR_REGISTRY }}/${{ env.ACR_NAMESPACE }}/backend:prod-v${{ needs.detect-changes.outputs.backend_version }}"
          echo "image=$IMAGE" >> $GITHUB_OUTPUT
          echo "ğŸ³ Built image: $IMAGE"

  # Build and push frontend image
  build-frontend:
    name: Build Frontend
    needs: detect-changes
    if: needs.detect-changes.outputs.frontend == 'true'
    runs-on: ubuntu-latest
    outputs:
      image: ${{ steps.build.outputs.image }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Azure ACR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.ACR_REGISTRY }}
          username: ${{ secrets.AZURE_ACR_USERNAME }}
          password: ${{ secrets.AZURE_ACR_PASSWORD }}

      - name: Build and Push Frontend
        id: build
        uses: docker/build-push-action@v6
        with:
          context: ./frontend
          file: ./frontend/Dockerfile
          target: production
          push: true
          tags: |
            ${{ env.ACR_REGISTRY }}/${{ env.ACR_NAMESPACE }}/frontend:prod-v${{ needs.detect-changes.outputs.frontend_version }}
            ${{ env.ACR_REGISTRY }}/${{ env.ACR_NAMESPACE }}/frontend:prod-${{ github.sha }}
            ${{ env.ACR_REGISTRY }}/${{ env.ACR_NAMESPACE }}/frontend:prod-latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Output image tag
        run: |
          IMAGE="${{ env.ACR_REGISTRY }}/${{ env.ACR_NAMESPACE }}/frontend:prod-v${{ needs.detect-changes.outputs.frontend_version }}"
          echo "image=$IMAGE" >> $GITHUB_OUTPUT
          echo "ğŸ³ Built image: $IMAGE"

  # Deploy to ACK (Alibaba Cloud Kubernetes)
  deploy:
    name: Deploy to ACK
    needs: [detect-changes, build-backend, build-frontend]
    # Run if at least one build succeeded (using always() to check even if one was skipped)
    if: |
      always() &&
      (needs.build-backend.result == 'success' || needs.build-frontend.result == 'success')
    runs-on: ubuntu-latest
    environment: production

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'v1.28.0'

      - name: Configure kubeconfig
        run: |
          mkdir -p ~/.kube
          echo "${{ secrets.ACK_KUBECONFIG }}" | base64 -d > ~/.kube/config
          chmod 600 ~/.kube/config

      - name: Verify cluster connection
        run: |
          echo "ğŸ”— Connecting to ACK cluster..."
          kubectl cluster-info
          kubectl get nodes

      - name: Update Kustomization
        run: |
          cd .pipeline/k8s/overlays/prod

          # Update backend image if it was built
          # Use context-aware sed to only update the backend entry (not frontend)
          if [ "${{ needs.build-backend.result }}" = "success" ]; then
            echo "ğŸ“ Updating backend image to prod-v${{ needs.detect-changes.outputs.backend_version }}"
            sed -i '/klinecubic\/backend$/{n;s|newTag:.*|newTag: "prod-v${{ needs.detect-changes.outputs.backend_version }}"|;}' kustomization.yaml
          fi

          # Update frontend image if it was built
          # Use context-aware sed to only update the frontend entry (not backend)
          if [ "${{ needs.build-frontend.result }}" = "success" ]; then
            echo "ğŸ“ Updating frontend image to prod-v${{ needs.detect-changes.outputs.frontend_version }}"
            sed -i '/klinecubic\/frontend$/{n;s|newTag:.*|newTag: "prod-v${{ needs.detect-changes.outputs.frontend_version }}"|;}' kustomization.yaml
          fi

          echo "ğŸ“‹ Updated kustomization.yaml:"
          cat kustomization.yaml | grep -A6 "images:"

      - name: Setup Kustomize
        uses: imranismail/setup-kustomize@v2
        with:
          kustomize-version: '5.3.0'

      - name: Pre-pull images (cache warming with DaemonSet)
        run: |
          echo "ğŸ”¥ Pre-pulling images to ALL nodes via DaemonSet..."

          # Pre-pull backend image if it was built
          if [ "${{ needs.build-backend.result }}" = "success" ]; then
            BACKEND_IMAGE="${{ env.ACR_REGISTRY }}/${{ env.ACR_NAMESPACE }}/backend:prod-v${{ needs.detect-changes.outputs.backend_version }}"
            echo "ğŸ“¦ Pre-pulling backend to all nodes: $BACKEND_IMAGE"

            # Create DaemonSet to pull image on ALL nodes
            cat <<EOF | kubectl apply -f -
          apiVersion: apps/v1
          kind: DaemonSet
          metadata:
            name: pre-pull-backend
            namespace: ${{ env.K8S_NAMESPACE }}
          spec:
            selector:
              matchLabels:
                app: pre-pull-backend
            template:
              metadata:
                labels:
                  app: pre-pull-backend
              spec:
                imagePullSecrets:
                - name: acr-secret
                initContainers:
                - name: pre-pull
                  image: $BACKEND_IMAGE
                  command: ["echo", "Backend image cached on this node"]
                  resources:
                    requests:
                      cpu: "10m"
                      memory: "16Mi"
                    limits:
                      cpu: "100m"
                      memory: "64Mi"
                containers:
                - name: pause
                  image: registry.cn-shanghai.aliyuncs.com/acs/pause:3.5
                  resources:
                    requests:
                      cpu: "1m"
                      memory: "4Mi"
                tolerations:
                - operator: Exists
          EOF

            # Wait for DaemonSet to be ready (all pods running = images cached)
            echo "â³ Waiting for backend image to be cached on all nodes (up to 20 min)..."
            for i in $(seq 1 40); do
              DESIRED=$(kubectl get daemonset pre-pull-backend -n ${{ env.K8S_NAMESPACE }} -o jsonpath='{.status.desiredNumberScheduled}' 2>/dev/null || echo "0")
              READY=$(kubectl get daemonset pre-pull-backend -n ${{ env.K8S_NAMESPACE }} -o jsonpath='{.status.numberReady}' 2>/dev/null || echo "0")
              echo "  DaemonSet status: $READY/$DESIRED ready"
              if [ "$DESIRED" != "0" ] && [ "$READY" = "$DESIRED" ]; then
                echo "âœ… Backend image cached on all $DESIRED nodes"
                break
              fi
              sleep 30
            done

            # Clean up DaemonSet after caching
            kubectl delete daemonset pre-pull-backend -n ${{ env.K8S_NAMESPACE }} --ignore-not-found
          fi

          # Pre-pull frontend image if it was built
          if [ "${{ needs.build-frontend.result }}" = "success" ]; then
            FRONTEND_IMAGE="${{ env.ACR_REGISTRY }}/${{ env.ACR_NAMESPACE }}/frontend:prod-v${{ needs.detect-changes.outputs.frontend_version }}"
            echo "ğŸ“¦ Pre-pulling frontend to all nodes: $FRONTEND_IMAGE"

            cat <<EOF | kubectl apply -f -
          apiVersion: apps/v1
          kind: DaemonSet
          metadata:
            name: pre-pull-frontend
            namespace: ${{ env.K8S_NAMESPACE }}
          spec:
            selector:
              matchLabels:
                app: pre-pull-frontend
            template:
              metadata:
                labels:
                  app: pre-pull-frontend
              spec:
                imagePullSecrets:
                - name: acr-secret
                initContainers:
                - name: pre-pull
                  image: $FRONTEND_IMAGE
                  command: ["echo", "Frontend image cached on this node"]
                  resources:
                    requests:
                      cpu: "10m"
                      memory: "16Mi"
                    limits:
                      cpu: "100m"
                      memory: "64Mi"
                containers:
                - name: pause
                  image: registry.cn-shanghai.aliyuncs.com/acs/pause:3.5
                  resources:
                    requests:
                      cpu: "1m"
                      memory: "4Mi"
                tolerations:
                - operator: Exists
          EOF

            echo "â³ Waiting for frontend image to be cached on all nodes..."
            for i in $(seq 1 40); do
              DESIRED=$(kubectl get daemonset pre-pull-frontend -n ${{ env.K8S_NAMESPACE }} -o jsonpath='{.status.desiredNumberScheduled}' 2>/dev/null || echo "0")
              READY=$(kubectl get daemonset pre-pull-frontend -n ${{ env.K8S_NAMESPACE }} -o jsonpath='{.status.numberReady}' 2>/dev/null || echo "0")
              echo "  DaemonSet status: $READY/$DESIRED ready"
              if [ "$DESIRED" != "0" ] && [ "$READY" = "$DESIRED" ]; then
                echo "âœ… Frontend image cached on all $DESIRED nodes"
                break
              fi
              sleep 30
            done

            kubectl delete daemonset pre-pull-frontend -n ${{ env.K8S_NAMESPACE }} --ignore-not-found
          fi

          echo "âœ… Image cache warming complete on all nodes"

      - name: Deploy to Kubernetes
        run: |
          echo "ğŸš€ Deploying to ACK..."
          # Use kustomize build with --load-restrictor flag, then pipe to kubectl apply
          kustomize build .pipeline/k8s/overlays/prod --load-restrictor=LoadRestrictionsNone | kubectl apply -f -

          # Restart deployments that were updated
          if [ "${{ needs.build-backend.result }}" = "success" ]; then
            echo "â™»ï¸ Restarting backend deployment..."
            kubectl rollout restart deployment/backend -n ${{ env.K8S_NAMESPACE }}
          fi

          if [ "${{ needs.build-frontend.result }}" = "success" ]; then
            echo "â™»ï¸ Restarting frontend deployment..."
            kubectl rollout restart deployment/frontend -n ${{ env.K8S_NAMESPACE }}
          fi

      - name: Wait for rollout
        run: |
          echo "â³ Waiting for deployments to be ready..."

          if [ "${{ needs.build-backend.result }}" = "success" ]; then
            kubectl rollout status deployment/backend -n ${{ env.K8S_NAMESPACE }} --timeout=600s
          fi

          if [ "${{ needs.build-frontend.result }}" = "success" ]; then
            kubectl rollout status deployment/frontend -n ${{ env.K8S_NAMESPACE }} --timeout=600s
          fi

      - name: Verify deployment
        run: |
          echo "ğŸ“Š Deployment Status:"
          kubectl get pods -n ${{ env.K8S_NAMESPACE }} -l "app in (backend, frontend)"

          echo ""
          echo "ğŸ” Pod Details:"
          kubectl get pods -n ${{ env.K8S_NAMESPACE }} -o wide

      - name: Health check
        run: |
          echo "ğŸ¥ Running health checks..."

          # Wait for services to be ready
          sleep 15

          # Check backend health via pod exec
          BACKEND_POD=$(kubectl get pods -n ${{ env.K8S_NAMESPACE }} -l app=backend -o jsonpath='{.items[0].metadata.name}')
          if [ -n "$BACKEND_POD" ]; then
            kubectl exec -n ${{ env.K8S_NAMESPACE }} $BACKEND_POD -- curl -sf http://localhost:8000/api/health && echo "âœ… Backend healthy" || echo "âš ï¸ Backend health check failed"
          fi

      - name: Deployment summary
        if: always()
        run: |
          echo ""
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "                  DEPLOYMENT SUMMARY                    "
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "ğŸŒ Production URL: https://klinecubic.cn"
          echo ""
          if [ "${{ needs.build-backend.result }}" = "success" ]; then
            echo "âœ… Backend:  prod-v${{ needs.detect-changes.outputs.backend_version }}"
          else
            echo "â­ï¸ Backend:  (no changes)"
          fi
          if [ "${{ needs.build-frontend.result }}" = "success" ]; then
            echo "âœ… Frontend: prod-v${{ needs.detect-changes.outputs.frontend_version }}"
          else
            echo "â­ï¸ Frontend: (no changes)"
          fi
          echo ""
          echo "ğŸ“ Commit: ${{ github.sha }}"
          echo "ğŸ‘¤ Author: ${{ github.actor }}"
          echo ""
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
