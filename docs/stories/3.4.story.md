# Story 3.4: Auto-Generate Meaningful Chat Titles

> **Story Type**: Enhancement
> **Epic**: Platform Quality & UX Polish
> **Created**: 2025-01-10
> **Status**: Done
> **Priority**: Low
> **Estimated Effort**: Small (1-2 days)

---

## Problem Statement

All chat conversations display "New chat" as the title, making it impossible for users to identify and navigate between conversations. Users analyzing multiple stocks cannot distinguish their chat history.

**Current State**: Every chat shows "New chat"
**Desired State**: Chats show contextual titles like "MRVL Analysis" or "AAPL Cash Flow Review"

---

## Story

**As a** user with multiple chat conversations,
**I want** chat titles to automatically reflect the content discussed,
**So that** I can easily find and return to previous analyses.

---

## Acceptance Criteria

- [x] **AC1**: New chats get auto-generated title after first LLM response
- [x] **AC2**: Title includes primary symbol if detected (e.g., "MRVL Analysis")
- [x] **AC3**: Title includes brief context from conversation (2-4 words)
- [x] **AC4**: Title generation does NOT add latency to chat response
- [x] **AC5**: Users can still manually edit titles (existing functionality)
- [x] **AC6**: Existing "New chat" titles remain unchanged (no migration)

---

## Technical Design

### Title Generation Logic

```python
def generate_chat_title(
    user_message: str,
    assistant_response: str,
    detected_symbols: list[str]
) -> str:
    """
    Generate a meaningful chat title.

    Priority:
    1. Symbol + Action: "AAPL Technical Analysis"
    2. Symbol only: "MRVL Analysis"
    3. Topic: "Portfolio Review"
    4. Fallback: "Chat - {timestamp}"

    Max length: 50 characters
    """
```

### Option A: Heuristic-Based Generation (Fallback)

Uses regex symbol extraction + keyword matching. No LLM call, zero latency impact.
Used as fallback when LLM doesn't provide a title.

```python
# title_utils.py - heuristic extraction
symbols = extract_symbols(user_message)  # regex: r"\b[A-Z]{1,5}\b"
action = detect_action(user_message)     # keyword matching
title = f"{symbols[0]} {action}"         # "AAPL Technical Analysis"
```

### Option B: LLM Structured Output (✅ IMPLEMENTED)

LLM generates title at end of every response. No extra LLM call, more accurate.

```python
# System prompt instructs LLM to append title:
# [chat_title: AAPL Technical Analysis]

# In react_agent.py - extract title from response
llm_title, final_answer = extract_title_from_response(raw_answer)

# Update chat title (LLM title preferred, heuristic fallback)
await chat_service.update_title_if_new(
    chat_id=chat_id,
    llm_title=llm_title,
    user_message=request.message,
)
```

**Implementation**: LLM generates contextual title as part of response. Title is extracted and stripped before display/storage. Falls back to heuristic if LLM doesn't include title.

### Symbol Detection

```python
import re

SYMBOL_PATTERN = re.compile(r'\b[A-Z]{1,5}\b')

def extract_symbols(text: str) -> list[str]:
    """Extract likely stock symbols from text."""
    candidates = SYMBOL_PATTERN.findall(text)
    # Filter common words that look like symbols
    stop_words = {"I", "A", "THE", "AND", "OR", "FOR", "TO", "IN", "ON", "AT"}
    return [s for s in candidates if s not in stop_words]
```

### Action Detection

```python
ACTION_KEYWORDS = {
    "technical": ["sma", "ema", "rsi", "macd", "chart", "technical"],
    "fundamental": ["earnings", "revenue", "cash flow", "balance sheet", "p/e"],
    "news": ["news", "sentiment", "headlines"],
    "price": ["price", "quote", "stock price"],
}

def detect_action(text: str) -> str:
    text_lower = text.lower()
    for action, keywords in ACTION_KEYWORDS.items():
        if any(kw in text_lower for kw in keywords):
            return action
    return "analysis"
```

---

## Example Titles

| User Message | Generated Title |
|--------------|-----------------|
| "Analyze AAPL stock" | "AAPL Analysis" |
| "What's the cash flow for MRVL?" | "MRVL Cash Flow" |
| "Show me NVDA technical indicators" | "NVDA Technical Analysis" |
| "Latest news on Tesla" | "TSLA News" |
| "Compare GOOGL and META" | "GOOGL vs META" |
| "How's my portfolio doing?" | "Portfolio Review" |

---

## Tasks

- [x] **Task 1**: Implement `extract_symbols()` utility function
- [x] **Task 2**: Implement `detect_action()` utility function
- [x] **Task 3**: Implement `generate_chat_title()` function
- [x] **Task 4**: Integrate title generation into chat flow (after first response)
- [x] **Task 5**: Update chat service to save generated title
- [x] **Task 6**: Add unit tests for title generation
- [x] **Task 7**: Test with real chat scenarios

---

## Files to Modify

```
backend/
├── src/services/chat_service.py      # Add title generation call
├── src/core/utils/title_utils.py     # NEW: Title generation utilities
└── tests/test_title_generation.py    # NEW: Unit tests

frontend/
└── (No changes - title display already works)
```

---

## Verification

```bash
# 1. Start new chat
# 2. Send message: "Analyze AAPL earnings"
# 3. Verify chat list shows "AAPL Earnings" (not "New chat")
# 4. Check database: chat.title updated
```

---

## Out of Scope

- Migrating existing "New chat" titles
- User-editable title suggestions
- Multi-language title support

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-10 | 1.0 | Story created from production issue | Bob (SM) |
| 2025-01-10 | 1.1 | Implementation completed (heuristic-based) | James (Dev) |
| 2025-01-10 | 1.2 | Fixed asyncio.create_task issue in streaming context | James (Dev) |
| 2025-01-10 | 1.3 | E2E verification with Playwright | James (Dev) |
| 2025-01-10 | 1.4 | Upgraded to LLM structured output (Option B) | James (Dev) |
| 2025-01-10 | 1.5 | Code cleanup, review complete, status → Done | James (Dev) |

---

## Dev Agent Record

### Agent Model Used

Claude Opus 4.5 (claude-opus-4-5-20251101)

### Debug Log References

- No debug issues encountered

### Completion Notes

1. **LLM Structured Output (Option B)**: System prompt instructs LLM to append title:
   - Format: `[chat_title: Your Title Here]` at end of every response
   - Title extracted via `extract_title_from_response()` regex pattern
   - Cleaned response (without title line) is displayed/stored
   - No extra LLM call - title is part of main response

2. **Title Utilities Module**: `src/core/utils/title_utils.py`:
   - `extract_title_from_response()` - NEW: Extracts LLM-generated title from response
   - `extract_symbols()` - Extracts stock symbols (fallback heuristic)
   - `detect_action()` - Detects analysis type (fallback heuristic)
   - `generate_chat_title()` - Generates fallback titles

3. **Chat Service Integration**: Added to `chat_service.py`:
   - `update_title_if_new()` - NEW: Priority: LLM title > Heuristic fallback
   - `generate_and_update_title()` - DEPRECATED: Use update_title_if_new() instead

4. **Streaming Handler Integration**: Updated in `react_agent.py`:
   - Extracts LLM title from raw response before streaming
   - Streams cleaned response (without title line)
   - Saves cleaned response to database
   - Updates title with LLM value (or heuristic fallback)

5. **Comprehensive Tests**: 44 unit tests in `test_title_generation.py`:
   - Symbol extraction (9 tests)
   - Action detection (9 tests)
   - Title generation (10 tests)
   - Edge cases (5 tests)
   - LLM title extraction (11 tests) - NEW

### File List

**Created:**
- `backend/src/core/utils/title_utils.py` - Title generation utilities
- `backend/tests/test_title_generation.py` - Unit tests (44 tests)

**Modified:**
- `backend/src/agent/llm_client.py` - Added title generation instruction to system prompt
- `backend/src/services/chat_service.py` - Added `update_title_if_new()` method
- `backend/src/api/chat/streaming/react_agent.py` - Integrated LLM title extraction

### Verification

```bash
# All 987 tests pass (44 title tests)
python -m pytest tests/ -q
# 987 passed, 73 warnings

# Lint passes
ruff check src/core/utils/title_utils.py src/services/chat_service.py src/agent/llm_client.py
# All checks passed!
```
