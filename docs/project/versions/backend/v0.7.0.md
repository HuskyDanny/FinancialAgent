# Backend v0.7.0

**Release Date**: 2025-11-15
**Docker Image**: `financial-agent/backend:0.7.0`

## Overview

Major enhancement to agent mode chat experience with real-time tool execution visibility and strategic tool calling. This release introduces a callback-based streaming architecture that provides users with live progress updates as the ReAct agent executes tools, combined with improved prompt engineering for more intelligent, context-driven tool selection.

## Features Added

### Real-time Tool Execution Streaming
- **ToolExecutionCallback Handler**: New async callback handler integrating with LangGraph's `AsyncCallbackHandler` to intercept tool execution lifecycle events
  - Captures `on_tool_start`, `on_tool_end`, and `on_tool_error` events
  - Streams events via asyncio.Queue for real-time SSE delivery
  - Includes rich metadata: tool name, icon, display name, symbol, inputs, duration, status
  - Located in `backend/src/agent/callbacks/tool_execution_callback.py`

- **Concurrent SSE Streaming**: Modified chat streaming endpoint to run agent execution and event streaming concurrently
  - Background generator continuously drains event queue with 0.1s timeout
  - Tool events stream immediately to frontend during agent execution (not after completion)
  - Prevents blocking behavior that delayed tool visibility
  - Implemented in `backend/src/api/chat.py` (lines 741-810)

- **Enhanced LangGraph Integration**: Updated `FinancialAnalysisReActAgent` to accept additional callbacks
  - `additional_callbacks` parameter in `ainvoke()` method
  - Merges custom callbacks with existing Langfuse handler
  - Enables extensible callback architecture for future enhancements

### Strategic Tool Calling Guidance
- **Prompt Engineering**: Added strategic guidance to system prompt for intelligent tool selection
  - **Phase-based approach**: Start broad (overview, market movers) â†’ go deep (balance sheet, technical analysis)
  - **Execution limits**: Maximum 3 tools per iteration to prevent overwhelming API calls
  - **Sequential reasoning**: Agent reasons about results before calling next tool batch
  - **Purpose-driven**: Only calls tools necessary for answering the question
  - Example: If overview + sentiment provide clear answer, agent stops without calling financials
  - Located in `backend/src/agent/llm_client.py` (FINANCIAL_AGENT_SYSTEM_PROMPT)

### Tool Event Schema
New SSE event types for tool execution tracking:
- `tool_start`: Tool invocation initiated with inputs and metadata
- `tool_end`: Tool completed successfully with output and duration
- `tool_error`: Tool failed with error message and duration

Event structure includes:
```json
{
  "type": "tool_start|tool_end|tool_error",
  "tool_name": "get_market_movers",
  "display_name": "Market Movers",
  "icon": "ðŸ“ˆ",
  "symbol": "AAPL",
  "inputs": {...},
  "output": "...",
  "duration_ms": 883,
  "run_id": "uuid-v4",
  "timestamp": "2025-11-14T23:20:53Z"
}
```

## Technical Details

### Concurrent Streaming Architecture
**Before (Sequential - Broken)**:
```python
result = await agent.ainvoke(...)  # Wait for completion
async for tool_event in stream_tool_events():  # THEN stream
    yield tool_event
```

**After (Concurrent - Fixed)**:
```python
# Create non-blocking agent task
agent_task = asyncio.create_task(agent.ainvoke(...))

# Stream events concurrently while agent runs
async for tool_event in stream_tool_events_background():
    yield tool_event
    if agent_task.done():
        break

result = await agent_task
```

### Callback Handler Implementation
- Inherits from `langchain_core.callbacks.AsyncCallbackHandler`
- Thread-safe event queue using `asyncio.Queue`
- Tracks active tools by UUID run_id
- Extracts tool metadata from registry for rich display
- Timestamps all events for debugging and analytics

### Performance Impact
- Tool events add minimal overhead (<5ms per event)
- Concurrent streaming reduces perceived latency (users see progress immediately)
- Event queue is bounded to prevent memory issues during long agent runs
- Background generator uses 0.1s timeout to balance responsiveness vs CPU usage

## Bug Fixes

- **Tool events not streaming in real-time**: Fixed by changing from sequential to concurrent execution pattern
  - Previous implementation buffered all events until agent completion
  - Now streams events immediately as they occur during execution
  - Verified with backend logs showing "Tool event streamed in real-time" debug messages

## Breaking Changes

None - All changes are additive and backward compatible.

## Compatibility

| Component | Required Version |
|-----------|-----------------|
| Frontend | >= 0.10.0 (for tool progress display) |
| MongoDB | 7.0+ |
| Redis | 7.2+ |
| Python | 3.12+ |
| LangChain Core | >= 0.1.0 |
| LangGraph | >= 0.0.1 |

## Known Issues

None

## Migration Guide

No migration required. Existing chat sessions will continue to work without changes.

**To enable tool progress display:**
1. Ensure frontend is updated to v0.10.0+
2. Set `agent_version: "v3"` in chat requests (default)
3. Tool progress will automatically appear in agent mode chats

## Testing

Verified with curl test showing proper event sequence:
```bash
# Expected output:
# 1. chat_created event
# 2. tool_start event (with icon, display name)
# 3. tool_end event (with duration, output)
# 4. chunk events (agent response)
# 5. done event
```

Backend logs confirm real-time streaming:
```
23:20:52 - ReAct agent invocation started
23:20:53 - Tool execution started (get_market_movers)
23:20:53 - Tool event streamed in real-time (tool_start) âœ…
23:20:54 - Tool execution completed (883ms)
23:20:54 - Tool event streamed in real-time (tool_end) âœ…
23:21:05 - ReAct agent invocation completed
```

## Related Changes

- Frontend v0.10.0: Added `ToolExecutionProgress` component for visual display
- See docs/features/real-time-tool-streaming.md for complete feature specification
